# encoding:utf-8

vocab_min_count = 10
word_vocab_size = 2500
word_embed_size = 64
batch_size = 50
rnn_cell_size = 128
max_seq_len = 60
att_da = 64
att_r = 64
mlp_hidden_size = 256
num_class = 2
keep_prob = 0.80
keep_prob1 = 0.75
keep_prob2 = 0.75
keep_prob3 = 0.75
keep_prob4 = 0.75
# LAMBDA_L2 = 1.2e-5
lambda_l2 = 0.0
learning_rate = 1.0e-3
epoch_size = 30
